# ğŸ›¡ï¸ Fraud Detection Platform (ML + Risk Engine + Dashboard)

An end-to-end **enterprise-style fraud detection system** built from scratch.  
This project combines:

- Machine Learning (XGBoost classifier)
- Unsupervised Anomaly Detection (IsolationForest)
- Risk-tier decision engine
- FastAPI scoring service
- Logging + audit trail storage
- Streamlit case-review dashboard
- Human-in-the-loop **fraud labeling workflow**

Designed for beginners learning production-grade ML systems, but structured like a real fintech backend.

---

## ğŸš€ Features

### ğŸ”¹ Fraud Scoring Engine
- Extracts behavioral features (amount, hour-of-day, recency gaps, etc.)
- Uses:
  - **XGBoost** for supervised fraud probability
  - **IsolationForest** for anomaly score
- Produces a combined **final risk score**

### ğŸ”¹ Risk Policy Layer
Risk tiers instead of binary outputs:

| Risk Level  | Action   |
|-----------|---------|
| low       | allow   |
| elevated  | review  |
| medium    | review  |
| high      | block   |
| critical  | block   |

### ğŸ”¹ Explainability
Each decision includes human-readable reasons like:
"High amount compared to user history"
"Unusual transaction hour"
"Short interval since previous transaction"


### ğŸ”¹ API Service (FastAPI)
Endpoints:
- `GET /` health check
- `POST /score` â†’ returns scores, risk, action, explanation

### ğŸ”¹ Event Logging
Every scored transaction is stored in: logs/events.csv


Includes:
- features
- scores
- decision
- explanation
- analyst label (fraud / legit / unknown)

### ğŸ”¹ Case Viewer Dashboard (Streamlit)
- View scored transactions
- Filter by risk + action
- Inspect case details
- Assign **labels** for retraining dataset

---

## ğŸ§© Project Structure

Fraud_platform/
â”‚
â”œâ”€â”€ data/ # training + sample data
â”œâ”€â”€ models/ # trained model files
â”œâ”€â”€ logs/
â”‚ â””â”€â”€ events.csv # scored transaction history
â”‚
â”œâ”€â”€ src/
â”‚ â”œâ”€â”€ features.py # feature engineering
â”‚ â”œâ”€â”€ train.py # model training
â”‚ â”œâ”€â”€ predict.py # scoring pipeline
â”‚ â”œâ”€â”€ risk.py # risk tier classifier
â”‚ â”œâ”€â”€ logger.py # event logging
â”‚ â”œâ”€â”€ score_api.py # FastAPI service
â”‚ â””â”€â”€ dashboard.py # Streamlit case viewer
â”‚
â””â”€â”€ README.md


---

## âš™ï¸ Installation

```bash
git clone <repo>
cd Fraud_platform
pip install -r requirements.txt

ğŸ‹ï¸ Train Model
python src/train.py


Models are saved into:

models/

ğŸ§  Run Fraud Scoring API
uvicorn src.score_api:app --reload


Open:

http://127.0.0.1:8000/docs


Send a test transaction via Swagger UI.

ğŸ“Š Run Case Viewer Dashboard
streamlit run src/dashboard.py


Open:

http://localhost:8501


You can:

inspect transactions

see scores & risk level

assign labels (fraud / legit / unknown)

Labels are written back into logs/events.csv.

ğŸ” Retraining Workflow (Human-in-Loop)

Model scores transactions

Analysts label cases in dashboard

Labeled rows become retraining dataset

Train updated model using real outcomes

This mirrors real-world fraud ops pipelines.

ğŸ› ï¸ Tech Stack

Python

Pandas

XGBoost

Scikit-learn

FastAPI

Streamlit

Joblib

ğŸ¯ Future Enhancements (Roadmap)

drift monitoring

model versioning

streaming transaction simulator

case comments & review audit log

auto-retraining pipeline

ensemble calibration metrics

database instead of CSV logs

ğŸ“Œ Educational Purpose

This project is for learning ML engineering, system design, and fraud analytics concepts â€” not production banking use.

ğŸ¤ Contributions

Pull requests welcome. Donâ€™t break things carelessly. The system already does that on its own sometimes.

ğŸ§‘â€ğŸ’» Author

Built as a guided learning project to understand:

ML pipelines

backend integration

risk engineering

explainable AI

dashboard tooling


